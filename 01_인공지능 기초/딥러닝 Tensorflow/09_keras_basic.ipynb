{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86ef924b-b871-4762-b663-34214dfd8fcd",
   "metadata": {},
   "source": [
    "# Keras Basic\n",
    "### * Sequential Layer 의 주요 레이어 정리 \n",
    "#### [1]  Dense Layer : Fully Connected Layer, layer의 입력과 출력 사이에 있는 모든 뉴런이 서로 연결 되는 Layer\n",
    "#### [2]  Flatten Layer : 다차원(4차원)을 2차원으로 축소하여 FC Layer에 전달한다\n",
    "#### [3]  Conv2D Layer : 이미지 특징을 추출하는 Convolution Layer \n",
    "#### [4]  MaxPool2D Layer : 중요 데이터(값이 큰 데이터)를 subsampling 하는 Layer\n",
    "#### [5]  Dropout Layer : 학습시 신경망의 과적합을 막기위해 일부 뉴런을 제거하는 Layer\n",
    "\n",
    "#### https://greeksharifa.github.io/keras/2018/06/29/Keras-Tutorial/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd65296c-0dcc-4ec8-8304-5fb511e7acc6",
   "metadata": {},
   "source": [
    "### [1] Dense Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cab8be6-028f-4a0c-8b91-77129cd91366",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf37b3db-3325-496e-98af-9aad675b98ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras 를 이용한 XOR 네트워크\n",
    "\n",
    "# train data set \n",
    "x_data = [[0,0],\n",
    "          [0,1],\n",
    "          [1,0],\n",
    "          [1,1]]   # (4,2)\n",
    "\n",
    "y_data = [[0],\n",
    "          [1],\n",
    "          [1],\n",
    "          [0]]     # (4,1)\n",
    "\n",
    "x_train = np.array(x_data,dtype=np.float32)\n",
    "y_train = np.array(y_data,dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e412d8df-1be2-4095-bb39-9e64cda8a03f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 4)                 12        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17\n",
      "Trainable params: 17\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Dense Layer 구현\n",
    "model = tf.keras.Sequential([ \n",
    "    # (4,2)*(2,4) = (4,4)\n",
    "    tf.keras.layers.Dense(units=4,activation='relu',input_shape=(2,)),\n",
    "    # (4,4)*(4,1) = (4,1)\n",
    "    tf.keras.layers.Dense(units=1,activation='sigmoid')\n",
    "])\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "639554bb-453e-45fc-9311-9f2143812531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4/4 [==============================] - 3s 2ms/step - loss: 0.7098 - accuracy: 0.5000\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7076 - accuracy: 0.2500\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7036 - accuracy: 0.2500\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.7035 - accuracy: 0.2500\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7016 - accuracy: 0.2500\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.7000 - accuracy: 0.2500\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6986 - accuracy: 0.5000\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6979 - accuracy: 0.5000\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6972 - accuracy: 0.5000\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6965 - accuracy: 0.5000\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6998 - accuracy: 0.5000\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6979 - accuracy: 0.5000\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6953 - accuracy: 0.5000\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6946 - accuracy: 0.5000\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6948 - accuracy: 0.5000\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6949 - accuracy: 0.5000\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6942 - accuracy: 0.5000\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6930 - accuracy: 0.5000\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6941 - accuracy: 0.5000\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6927 - accuracy: 0.5000\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6914 - accuracy: 0.5000\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6916 - accuracy: 0.5000\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6918 - accuracy: 0.5000\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6898 - accuracy: 0.5000\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6905 - accuracy: 0.5000\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6892 - accuracy: 0.5000\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6894 - accuracy: 0.5000\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.6880 - accuracy: 0.5000\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6889 - accuracy: 0.5000\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6886 - accuracy: 0.5000\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6869 - accuracy: 0.5000\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6860 - accuracy: 0.5000\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.6854 - accuracy: 0.5000\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6855 - accuracy: 0.5000\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6849 - accuracy: 0.5000\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6834 - accuracy: 0.5000\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6843 - accuracy: 0.5000\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6823 - accuracy: 0.5000\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6806 - accuracy: 0.5000\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.6823 - accuracy: 0.5000\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6801 - accuracy: 0.5000\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6778 - accuracy: 0.5000\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6770 - accuracy: 0.7500\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6761 - accuracy: 0.7500\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6751 - accuracy: 0.7500\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6758 - accuracy: 0.7500\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6730 - accuracy: 0.7500\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6716 - accuracy: 0.7500\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6706 - accuracy: 0.7500\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.6694 - accuracy: 0.7500\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6684 - accuracy: 0.7500\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6667 - accuracy: 0.7500\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6651 - accuracy: 0.7500\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6642 - accuracy: 0.7500\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6633 - accuracy: 0.7500\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6623 - accuracy: 0.7500\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6612 - accuracy: 0.7500\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6598 - accuracy: 0.7500\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6620 - accuracy: 0.7500\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.6577 - accuracy: 0.7500\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6582 - accuracy: 0.7500\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6544 - accuracy: 0.7500\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6530 - accuracy: 0.7500\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6519 - accuracy: 0.7500\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6528 - accuracy: 0.7500\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.6498 - accuracy: 0.7500\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6481 - accuracy: 0.7500\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6456 - accuracy: 0.7500\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6454 - accuracy: 0.7500\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6437 - accuracy: 0.7500\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.6421 - accuracy: 0.7500\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6401 - accuracy: 0.7500\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6395 - accuracy: 0.7500\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.6363 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6354 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.6326 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6304 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6296 - accuracy: 0.7500\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6268 - accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6261 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.6226 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.6214 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6228 - accuracy: 0.7500\n",
      "Epoch 84/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6192 - accuracy: 0.7500\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.6185 - accuracy: 0.7500\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.6151 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6128 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.6131 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6089 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.6062 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6059 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6048 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6007 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6018 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.5983 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5956 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5937 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5924 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5904 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5871 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c8df5b16c0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학습\n",
    "model.fit(x_train,y_train,epochs=100,batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "310382ce-2910-442c-8cf6-9ff9ac697f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 51ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예측\n",
    "preds = model.predict(x_train)\n",
    "np.round(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3de55cdf-6f23-4eba-8636-b4e278208f37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 234ms/step - loss: 0.5846 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5846245288848877, 1.0]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 평가\n",
    "model.evaluate(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ed2bbd-9ca9-434c-9ece-cc60de4f4e7e",
   "metadata": {},
   "source": [
    "### [2] Flatten Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19b58a26-a50e-43cd-9455-c2e53c8dd474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 28, 28, 10)\n",
      "(1000, 7840)\n"
     ]
    }
   ],
   "source": [
    "# 4차원 데이터를 2차원으로 축소하여 FC Layer에 전달\n",
    "data = np.arange(1000*28*28*10).reshape(1000,28,28,10).astype(np.float32)\n",
    "print(data.shape)  # (None,28,28,10)\n",
    "layer = tf.keras.layers.Flatten()\n",
    "outputs = layer(data)\n",
    "print(outputs.shape)   # (None, 28*28*10) = (None,7840)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a076ec7-3cf8-499f-8622-872c3a6e5825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 28, 28)\n",
      "(1000, 784)\n"
     ]
    }
   ],
   "source": [
    "# 3차원 데이터를 2차원으로 축소하여 FC Layer에 전달\n",
    "data = np.arange(1000*28*28).reshape(1000,28,28).astype(np.float32)\n",
    "print(data.shape)  # (None,28,28)\n",
    "layer = tf.keras.layers.Flatten()\n",
    "outputs = layer(data)\n",
    "print(outputs.shape)   # (None, 28*28) = (None,784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "67ad07b9-c756-41ed-83cd-c5506a33d832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28)\n",
      "(28, 28)\n"
     ]
    }
   ],
   "source": [
    "# 2차원 데이터는 그대로 2차원으로 FC Layer에 전달\n",
    "data = np.arange(28*28).reshape(28,28).astype(np.float32)\n",
    "print(data.shape) # (28, 28)\n",
    "layer = tf.keras.layers.Flatten()\n",
    "outputs = layer(data)\n",
    "print(outputs.shape) # (28,28) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f62065-dd50-46f9-a779-a6c5e3d5b886",
   "metadata": {},
   "source": [
    "### [3] Dropout Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e4117d6-a96d-49c0-b875-bafc3a76b287",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dropout\n",
    "# The Dropout layer randomly sets input units to 0 with a frequency of rate \n",
    "# at each step during training time, which helps prevent overfitting. \n",
    "# Inputs not set to 0 are scaled up by 1/(1 - rate) such that the sum over all inputs is unchanged.\n",
    "\n",
    "# Note that the Dropout layer only applies when training is set to True such that\n",
    "# no values are dropped during inference. When using model.fit, training will be\n",
    "# appropriately set to True automatically, and in other contexts, you can set \n",
    "# the kwarg explicitly to True when calling the layer.\n",
    "\n",
    "# (This is in contrast to setting trainable=False for a Dropout layer.\n",
    "# trainable does not affect the layer's behavior, as Dropout does not have any \n",
    "# variables/weights that can be frozen during training.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "61b29bab-3386-49c8-ab05-e24118510f6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1.]\n",
      " [2. 3.]\n",
      " [4. 5.]\n",
      " [6. 7.]\n",
      " [8. 9.]]\n",
      "tf.Tensor(\n",
      "[[ 0.  0.]\n",
      " [ 4.  6.]\n",
      " [ 0. 10.]\n",
      " [ 0. 14.]\n",
      " [16.  0.]], shape=(5, 2), dtype=float32)\n",
      "[[ 0.         1.4285715]\n",
      " [ 2.857143   4.285714 ]\n",
      " [ 5.714286   7.142857 ]\n",
      " [ 8.571428  10.       ]\n",
      " [11.428572  12.857143 ]]\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(0)\n",
    "data = np.arange(10).reshape(5,2).astype(np.float32)\n",
    "print(data)\n",
    "\n",
    "layer = tf.keras.layers.Dropout(0.3,input_shape=(2,))\n",
    "\n",
    "outputs = layer(data,training=True)\n",
    "# model.fit()호출 시는  학습 모드로 training=True가 되어 dropuout 적용\n",
    "# model.evaluate() 호출 시는 예측 모드로 False가 되어 dropuout이 수행되지 않음\n",
    "print(outputs) # 데이터의 30%는 0으로 나머지 데이터는  1/(1-0.3)으로 곱하여 scaled up된다\n",
    "print(data*1/(1 - 0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2ffaa8-46d7-4f94-bf12-d80137b2a279",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
