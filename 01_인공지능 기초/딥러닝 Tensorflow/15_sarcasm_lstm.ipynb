{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebd059d7-eae7-405f-9332-d63d6eb8103d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sarcasm json data binary classification\n",
    "# total 26,709 headlines  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19ce4649-55e7-43a3-80db-06f96f96eefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import tensorflow as tf\n",
    "import urllib\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a73df1f-b039-4cbc-b6e6-59d318bf37f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('sarcasm.json', <http.client.HTTPMessage at 0x29848fcfa90>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sarcasm.json 데이터셋 파일 다운로드 , Windows용\n",
    "url = 'https://storage.googleapis.com/download.tensorflow.org/data/sarcasm.json'\n",
    "urllib.request.urlretrieve(url, 'sarcasm.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cad9304e-bfb6-4b3b-ae2d-48f78bc866ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 파일 불러오기\n",
    "with open('sarcasm.json','r') as f:\n",
    "    datastore = json.load(f)\n",
    "\n",
    "sentences = []\n",
    "labels = []\n",
    "\n",
    "for item in datastore:\n",
    "    sentences.append(item['headline'])\n",
    "    labels.append(item['is_sarcastic'])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f301506b-cfe0-461b-8e92-de5a455dd427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "(26709, 2)\n",
      "is_sarcastic\n",
      "0    14985\n",
      "1    11724\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>is_sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>former versace store clerk sues over secret 'b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the 'roseanne' revival catches up to our thorn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mom starting to fear son's web series closest ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>boehner just wants wife to listen, not come up...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>j.k. rowling wishes snape happy birthday in th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>advancing the world's women</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>the fascinating case for eating lab-grown meat</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>this ceo will send your kids to school, if you...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>top snake handler leaves sinking huckabee camp...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>friday's morning email: inside trump's presser...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            headline  is_sarcastic\n",
       "0  former versace store clerk sues over secret 'b...             0\n",
       "1  the 'roseanne' revival catches up to our thorn...             0\n",
       "2  mom starting to fear son's web series closest ...             1\n",
       "3  boehner just wants wife to listen, not come up...             1\n",
       "4  j.k. rowling wishes snape happy birthday in th...             0\n",
       "5                        advancing the world's women             0\n",
       "6     the fascinating case for eating lab-grown meat             0\n",
       "7  this ceo will send your kids to school, if you...             0\n",
       "8  top snake handler leaves sinking huckabee camp...             1\n",
       "9  friday's morning email: inside trump's presser...             0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 프레임으로 보기\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(datastore)\n",
    "df = df.iloc[:,1:]\n",
    "\n",
    "print(type(datastore[0]))  # <class 'dict'>\n",
    "print(df.shape)            # (26709, 2)\n",
    "print(df['is_sarcastic'].value_counts())   # 0    14985 : not sarcastic \n",
    "                                           # 1    11724 : sarcastic\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b95a8b9-8fc2-4e23-9090-4ed81e3bd3c5",
   "metadata": {},
   "source": [
    "### 텍스트 전처리: Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27b9f647-7f32-450d-9bea-026f068a9191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리를 위한 변수 설정\n",
    "vocab_size = 10000    # 토큰화에 사용될 최대 어휘수\n",
    "embedding_dim = 16    # Embedding 계층의 output size \n",
    "max_length = 100      # 한 문장의 길이, 데이터 셋의 길이, maxlen\n",
    "trunc_type = 'post'   # maxlen보다 클때 잘라낼 유형, 'post' : 뒤쪽\n",
    "padding_type = 'post' # maxlen보다 작을때 0을 추가할 유형, 'post' : 뒤쪽\n",
    "oov_tok = \"<OOV>\"     # Out-Of-Vocabulary(단어 집합에 없는 단어)\n",
    "training_size = 20000 # 학습 데이터의 갯수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e3d65565-eb2f-4dcd-a462-b890d38d9c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train(20000)/test(6709) data split \n",
    "training_sentences = sentences[:training_size]\n",
    "training_labels = labels[:training_size]\n",
    "\n",
    "testing_sentences = sentences[training_size:]\n",
    "testing_labels = labels[training_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f88acf2b-161a-4b14-ba64-fae8b3f59005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 100)\n",
      "(6709, 100)\n"
     ]
    }
   ],
   "source": [
    "# 토큰나이저를 시행하여 단어를 숫자값, 인덱스로 변환하여 저장\n",
    "\n",
    "# 가장 빈도가 높은 10000개의 단어들만 사용하여 토큰화\n",
    "tokenizer = Tokenizer(num_words=vocab_size,oov_token=oov_tok)\n",
    "\n",
    "# 단어 인덱스를 구축 \n",
    "tokenizer.fit_on_texts(training_sentences)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "# print(word_index)\n",
    "\n",
    "# 문자열을 정수 인덱스의 리스트로 변환 : 정수 인코딩\n",
    "training_sequences = tokenizer.texts_to_sequences(training_sentences) # type은 list\n",
    "# print(training_sequences[0])\n",
    "\n",
    "# 패딩, 벡터 표현을 얻음 : 신경망에 입력할 X값\n",
    "training_padded = pad_sequences(training_sequences,maxlen=max_length,\n",
    "                                padding=padding_type,truncating=trunc_type)\n",
    "\n",
    "# print(training_padded[0])\n",
    "\n",
    "# test 데이터 : 정수 인덱스의 리스트로 변환\n",
    "testing_sequences = tokenizer.texts_to_sequences(testing_sentences)\n",
    "\n",
    "# test 데이터 : 벡터 표현을 얻음 \n",
    "testing_padded = pad_sequences(testing_sequences,maxlen=max_length,\n",
    "                                padding=padding_type,truncating=trunc_type)\n",
    "\n",
    "print(training_padded.shape)  # (20000, 100)\n",
    "print(testing_padded.shape)   # (6709, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "71efa61f-feb1-4107-99f2-67ab1f20b184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list를 array로 변환\n",
    "import numpy as np\n",
    "training_labels = np.array(training_labels)  # (20000,)\n",
    "testing_labels = np.array(testing_labels)    # (6709,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6801a687-f880-4081-b7cc-89f1109a1a84",
   "metadata": {},
   "source": [
    "### 학습모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1c276b4d-9218-46ab-8398-3aaaa33377d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 100, 16)           160000    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 160,000\n",
      "Trainable params: 160,000\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size,embedding_dim,input_length=max_length),\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153ddc03-19ec-4bc9-9aa4-0cc5423bb523",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
